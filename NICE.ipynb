{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205512d7-bd92-459f-a8ca-878fbe0077d3",
   "metadata": {},
   "source": [
    "# NICE\n",
    "\n",
    "This is an algorithm for compressing images, modeled as arrays of 8x8 RGB blocks, into much smaller latents.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Download the dataset from Kaggle. The dataset was built from COCO, where each image was sampled for 8x8 RGB blocks.\n",
    "The dataset consists of a training and validation split. Each split is a flat Nx3x8x8 tensor with an 8-bit integer data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535fb72-897a-46cf-bd7c-040215a69df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "datasets_path = Path(kagglehub.dataset_download('tay10r/image-block-compression'))\n",
    "\n",
    "import torch\n",
    "class BinDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This dataset is for sampling from .bin files containing an array of 3x8x8 blocks.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename: Path):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.__data = f.read()\n",
    "        self.__num_samples = len(self.__data) // (3 * 8 * 8)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.__num_samples\n",
    "\n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        s = 3 * 8 * 8\n",
    "        offset = index * s\n",
    "        block: bytes = self.__data[offset:offset+s]\n",
    "        # This will produce a warning about a non-writable tensor.\n",
    "        # It's annoying, but just try to ignore it.\n",
    "        return torch.frombuffer(block, dtype=torch.uint8, count=s).reshape(3, 8, 8)\n",
    "\n",
    "import numpy as np\n",
    "class RemoteImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_url: str):\n",
    "        import requests\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()\n",
    "        from PIL import Image\n",
    "        from io import BytesIO\n",
    "        self.__image = np.transpose(np.asarray(Image.open(fp=BytesIO(response.content))), axes=(2, 0, 1))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        C, H, W = self.__image.shape\n",
    "        y = H // 8\n",
    "        x = W // 8\n",
    "        return x * y\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        _, H, W = self.__image.shape\n",
    "        tiles_w = W // 8\n",
    "        tiles_h = H // 8\n",
    "        x = index % tiles_w\n",
    "        y = index // tiles_w\n",
    "        if y >= tiles_h:\n",
    "            raise IndexError(index)\n",
    "        y0 = (y + 0) * 8\n",
    "        y1 = (y + 1) * 8\n",
    "        x0 = (x + 0) * 8\n",
    "        x1 = (x + 1) * 8\n",
    "        return torch.from_numpy(self.__image[:, y0:y1, x0:x1])\n",
    "\n",
    "train_data = BinDataset(datasets_path / 'train.bin')\n",
    "val_data = BinDataset(datasets_path / 'val.bin')\n",
    "demo_data = RemoteImageDataset(image_url='https://raw.githubusercontent.com/mikolalysenko/baboon-image/master/baboon.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5c7a5",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "Now we'll define the network, which consists of an encoder and decoder.\n",
    "We define these as two separate networks, since in practice they are used separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden: int, num_bits: int):\n",
    "        super().__init__()\n",
    "        self.__layers = nn.Sequential(\n",
    "            nn.Linear(3 * 8 * 8, hidden, bias=False),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden, num_bits, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.__layers(x)\n",
    "        x = F.softsign(x)\n",
    "        bits = x > 0.0\n",
    "        bits = bits + x - x.detach()\n",
    "        return bits\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden: int, num_bits: int):\n",
    "        super().__init__()\n",
    "        self.__layers = nn.Sequential(\n",
    "            nn.Linear(num_bits, hidden, bias=False),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden, 8 * 8 * 3, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, bits: torch.Tensor) -> torch.Tensor:\n",
    "        x: torch.Tensor = self.__layers(bits)\n",
    "        x = x.reshape(x.shape[0], 3, 8, 8)\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_bits: int, encoder_hidden: int, decoder_hidden: int):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(hidden=encoder_hidden, num_bits=num_bits)\n",
    "        self.decoder = Decoder(hidden=decoder_hidden, num_bits=num_bits)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        bits = self.encoder(x)\n",
    "        #recon = self.decoder(F.softsign(bits))\n",
    "        recon = self.decoder(bits)\n",
    "        return recon, bits\n",
    "\n",
    "\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"compute device: {device_name}\")\n",
    "dev = torch.device(device_name)\n",
    "net = Net(num_bits=48, encoder_hidden=256, decoder_hidden=256).to(dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2accc",
   "metadata": {},
   "source": [
    "### Training the Network\n",
    "\n",
    "We're going to train on the COCO dataset. Since it's very large and takes a long time,\n",
    "we're going to break it up into 1000 iterations. So every 1000 training samples, we will\n",
    "check the validation loss and evaluate the demo image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import math\n",
    "\n",
    "def forward(net: Net, x: torch.Tensor) -> torch.Tensor:\n",
    "    y, z = net(x)\n",
    "    loss = torch.nn.functional.mse_loss(y, x)\n",
    "    return loss\n",
    "\n",
    "def val(net: Net, data: torch.utils.data.DataLoader, dev: torch.device) -> float:\n",
    "    net.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            x: torch.Tensor = batch\n",
    "            x = x.to(dev).float() * (1.0 / 255.0)\n",
    "            val_loss_sum += forward(net, x).item()\n",
    "    return val_loss_sum / len(data)\n",
    "\n",
    "def train(net: Net, train_data: torch.utils.data.Dataset, val_data: torch.utils.data.Dataset, dev: torch.device):\n",
    "    writer = SummaryWriter()\n",
    "    batch_size = 4096\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=1.0e-3)\n",
    "    counter = 0\n",
    "    net.train()\n",
    "    epochs = 16\n",
    "    best_loss = math.inf\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            x: torch.Tensor = batch\n",
    "            x = x.to(dev).float() * (1.0 / 255.0)\n",
    "            loss = forward(net, x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            counter += 1\n",
    "            if counter % 1000 == 0:\n",
    "                epoch += 1\n",
    "                val_loss = val(net, val_loader, dev)\n",
    "                writer.add_scalar('loss', val_loss, global_step=(counter // 1000))\n",
    "                writer.flush()\n",
    "                print(f'[{counter // 1000}]: {val_loss:.06f}')\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    torch.save(net.state_dict(), 'best_weights.pt')\n",
    "                net.train()\n",
    "\n",
    "train(net, train_data, val_data, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226e580",
   "metadata": {},
   "source": [
    "## Analyzing the Bit Distribution\n",
    "\n",
    "A fully utilized bit will average 0.5 across a large dataset.\n",
    "Let's verify and see how uniform our bit utilization is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bit_means(net, val_loader, dev):\n",
    "    net.eval()\n",
    "    num_bits = 48\n",
    "    sums = torch.zeros(num_bits, device=dev)\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch.to(dev).float() * (1.0 / 255.0)\n",
    "            _, bits = net(x)\n",
    "            sums += bits.sum(dim=0)\n",
    "            count += bits.shape[0]\n",
    "\n",
    "    means = (sums / count).cpu()\n",
    "    return means\n",
    "\n",
    "best_net = Net(num_bits=48, encoder_hidden=256, decoder_hidden=256)\n",
    "best_net.load_state_dict(torch.load('best_weights.pt'))\n",
    "best_net.to(dev)\n",
    "\n",
    "# usage\n",
    "means = bit_means(best_net, val_loader=torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False), dev=dev)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(range(len(means)), means.numpy())\n",
    "plt.axhline(0.5, linestyle='--')\n",
    "plt.title(\"Bit Activation Means (Validation Set)\")\n",
    "plt.xlabel(\"Bit Index\")\n",
    "plt.ylabel(\"Mean Activation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c5553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
